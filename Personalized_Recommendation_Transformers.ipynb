{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TSj6Zhto6v_y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8672e33d-2dbb-4965-d2da-57af91d7146a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.10/dist-packages/torchtext/utils.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import os\n",
        "from tempfile import TemporaryDirectory\n",
        "from typing import Tuple\n",
        "\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "from torch.utils.data import dataset\n",
        "from torchtext.vocab import vocab\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "from zipfile import ZipFile\n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.3.0 torchtext==0.18.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFNnPlSg6XrR",
        "outputId": "2d1f8026-9567-4fa9-dd19-b9c22cf051c8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.3.0\n",
            "  Using cached torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting torchtext==0.18.0\n",
            "  Using cached torchtext-0.18.0-cp310-cp310-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.0)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.0)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.0)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.0)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.0)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.3.0 (from torch==2.3.0)\n",
            "  Downloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.18.0) (4.66.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.18.0) (2.32.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.18.0) (1.26.4)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.3.0) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.18.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.18.0) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.18.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.18.0) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3.0) (1.3.0)\n",
            "Downloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchtext-0.18.0-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchtext\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.22.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.22.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.22.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.4.0+cu121 requires torch==2.4.0, but you have torch 2.3.0 which is incompatible.\n",
            "torchvision 0.19.0+cu121 requires torch==2.4.0, but you have torch 2.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.68 nvidia-nvtx-cu12-12.1.105 torch-2.3.0 torchtext-0.18.0 triton-2.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewsQzPX17M6i"
      },
      "source": [
        "# 1. Data Preprocessing\n",
        "In this section, we'll start by loading the MovieLens dataset. We will then construct vocabularies for movie IDs and user IDs, and create sequences of user interactions. These steps lay the groundwork for our recommendation model, converting the data into a format that our model can utilize effectively.\n",
        "## 1.1 Loading Dataset\n",
        "At first we will download our dataset to generate our sequences and vocabularies. Then user_id and movie_id values are processesed to fix their data types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4x3UJlOc7llA"
      },
      "outputs": [],
      "source": [
        "urlretrieve(\"http://files.grouplens.org/datasets/movielens/ml-1m.zip\", \"movielens.zip\")\n",
        "ZipFile(\"movielens.zip\", \"r\").extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppvDGJzE7MtC",
        "outputId": "d0f00de8-e62e-42c3-e752-4175c7ae5b73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-0a8b069686a2>:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  users = pd.read_csv(\n",
            "<ipython-input-6-0a8b069686a2>:8: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  ratings = pd.read_csv(\n",
            "<ipython-input-6-0a8b069686a2>:14: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  movies = pd.read_csv(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Datasets\n",
        "users = pd.read_csv(\n",
        "    \"ml-1m/users.dat\",\n",
        "    sep=\"::\",\n",
        "    names=[\"user_id\", \"sex\", \"age_group\", \"occupation\", \"zip_code\"],\n",
        ")\n",
        "\n",
        "ratings = pd.read_csv(\n",
        "    \"ml-1m/ratings.dat\",\n",
        "    sep=\"::\",\n",
        "    names=[\"user_id\", \"movie_id\", \"rating\", \"unix_timestamp\"],\n",
        ")\n",
        "\n",
        "movies = pd.read_csv(\n",
        "    \"ml-1m/movies.dat\", sep=\"::\", names=[\"movie_id\", \"title\", \"genres\"], encoding='latin-1'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "eJoH9z2D7L3k"
      },
      "outputs": [],
      "source": [
        "# Preventing ids to be written as integer or float data type\n",
        "users[\"user_id\"] = users[\"user_id\"].apply(lambda x: f\"user_{x}\")\n",
        "\n",
        "movies[\"movie_id\"] = movies[\"movie_id\"].apply(lambda x: f\"movie_{x}\")\n",
        "\n",
        "ratings[\"movie_id\"] = ratings[\"movie_id\"].apply(lambda x: f\"movie_{x}\")\n",
        "ratings[\"user_id\"] = ratings[\"user_id\"].apply(lambda x: f\"user_{x}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zE0CZxBN8IHK"
      },
      "source": [
        "## 1.2 Creating Vocabulary\n",
        "Now that we have our data ready, it's time to prepare our vocabularies for user IDs and movie IDs. This step will convert the unique IDs into numerical indices that our model can use. The following code snippet accomplishes this task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rcNNeirg8F2X"
      },
      "outputs": [],
      "source": [
        "# Genarting a list of unique movie ids\n",
        "movie_ids = movies.movie_id.unique()\n",
        "\n",
        "# Counter is used to feed movies to movive_vocab\n",
        "movie_counter = Counter(movie_ids)\n",
        "\n",
        "# Genarting vocabulary\n",
        "movie_vocab = vocab(movie_counter, specials=['<unk>'])\n",
        "\n",
        "# For indexing input ids\n",
        "movie_vocab_stoi = movie_vocab.get_stoi()\n",
        "\n",
        "# Movie to title mapping dictionary\n",
        "movie_title_dict = dict(zip(movies.movie_id, movies.title))\n",
        "\n",
        "# Similarly generating a vocabulary for user ids\n",
        "user_ids = users.user_id.unique()\n",
        "user_counter = Counter(user_ids)\n",
        "user_vocab = vocab(user_counter, specials=['<unk>'])\n",
        "user_vocab_stoi = user_vocab.get_stoi()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uxhd4YPy9WNX"
      },
      "source": [
        "## 1.3 Generating Sequences\n",
        "All interactions of users are first sorted by their interaction timestamp and then divided into sub sequences to train our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "d1OO4GqD8NX0"
      },
      "outputs": [],
      "source": [
        "# Group ratings by user_id in order of increasing unix_timestamp.\n",
        "ratings_group = ratings.sort_values(by=[\"unix_timestamp\"]).groupby(\"user_id\")\n",
        "\n",
        "ratings_data = pd.DataFrame(\n",
        "    data={\n",
        "        \"user_id\": list(ratings_group.groups.keys()),\n",
        "        \"movie_ids\": list(ratings_group.movie_id.apply(list)),\n",
        "        \"timestamps\": list(ratings_group.unix_timestamp.apply(list)),\n",
        "    }\n",
        ")\n",
        "\n",
        "# Sequence length, min history count and window slide size\n",
        "sequence_length = 4\n",
        "min_history = 1\n",
        "step_size = 2\n",
        "\n",
        "# Creating sequences from lists with sliding window\n",
        "def create_sequences(values, window_size, step_size, min_history):\n",
        "  sequences = []\n",
        "  start_index = 0\n",
        "  while len(values[start_index:]) > min_history:\n",
        "    seq = values[start_index : start_index + window_size]\n",
        "    sequences.append(seq)\n",
        "    start_index += step_size\n",
        "  return sequences\n",
        "\n",
        "ratings_data.movie_ids = ratings_data.movie_ids.apply(\n",
        "    lambda ids: create_sequences(ids, sequence_length, step_size, min_history)\n",
        ")\n",
        "\n",
        "\n",
        "del ratings_data[\"timestamps\"]\n",
        "\n",
        "# Sub-sequences are exploded.\n",
        "# Since there might be more than one sequence for each user.\n",
        "ratings_data_transformed = ratings_data[[\"user_id\", \"movie_ids\"]].explode(\n",
        "    \"movie_ids\", ignore_index=True\n",
        ")\n",
        "\n",
        "ratings_data_transformed.rename(\n",
        "    columns={\"movie_ids\": \"sequence_movie_ids\"},\n",
        "    inplace=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "q21pt9ww9seT",
        "outputId": "7d13f4b8-4107-45f3-ef79-cb720f073c46"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     user_id                                sequence_movie_ids\n",
              "0  user_2275  [movie_2333, movie_2676, movie_3053, movie_2013]\n",
              "1  user_3890   [movie_1580, movie_1885, movie_3039, movie_471]\n",
              "2  user_5783      [movie_353, movie_543, movie_471, movie_276]\n",
              "3  user_4057                            [movie_780, movie_673]\n",
              "4  user_3901  [movie_3301, movie_3285, movie_3326, movie_3180]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c14edc0-585c-4f90-8884-e7234a2c17cc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>sequence_movie_ids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>user_2275</td>\n",
              "      <td>[movie_2333, movie_2676, movie_3053, movie_2013]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>user_3890</td>\n",
              "      <td>[movie_1580, movie_1885, movie_3039, movie_471]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>user_5783</td>\n",
              "      <td>[movie_353, movie_543, movie_471, movie_276]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>user_4057</td>\n",
              "      <td>[movie_780, movie_673]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>user_3901</td>\n",
              "      <td>[movie_3301, movie_3285, movie_3326, movie_3180]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c14edc0-585c-4f90-8884-e7234a2c17cc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5c14edc0-585c-4f90-8884-e7234a2c17cc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5c14edc0-585c-4f90-8884-e7234a2c17cc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cb114044-a7e5-4f46-b22d-6a756dabfcf6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cb114044-a7e5-4f46-b22d-6a756dabfcf6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cb114044-a7e5-4f46-b22d-6a756dabfcf6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"ratings_data_transformed\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"user_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"user_3890\",\n          \"user_3901\",\n          \"user_5783\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sequence_movie_ids\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "ratings_data_transformed.sample(frac=1).reset_index(drop=True).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0wqTDXi_1vi"
      },
      "source": [
        "## 1.4 Train Test Split\n",
        "The data is split into training and testing sets. Although considering timestamps could potentially provide a more refined split, for the sake of simplicity, we opt for a random indexing approach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5WOLmSIz9tYQ"
      },
      "outputs": [],
      "source": [
        "# Random indexing\n",
        "random_selection = np.random.rand(len(ratings_data_transformed.index)) <= 0.85\n",
        "\n",
        "# Split train data\n",
        "df_train_data = ratings_data_transformed[random_selection]\n",
        "train_data_raw = df_train_data[[\"user_id\", \"sequence_movie_ids\"]].values\n",
        "\n",
        "# Split test data\n",
        "df_test_data = ratings_data_transformed[~random_selection]\n",
        "test_data_raw = df_test_data[[\"user_id\", \"sequence_movie_ids\"]].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVKMFIwd_6vK"
      },
      "source": [
        "DataLoader is defined to be used for training and evaluation as final pre-processing step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YAjJ0nTp_4uX"
      },
      "outputs": [],
      "source": [
        "# Pytorch Dataset for user interactions\n",
        "class MovieSeqDataset(Dataset):\n",
        "    # Initialize dataset\n",
        "    def __init__(self, data, movie_vocab_stoi, user_vocab_stoi):\n",
        "        self.data = data\n",
        "\n",
        "        self.movie_vocab_stoi = movie_vocab_stoi\n",
        "        self.user_vocab_stoi = user_vocab_stoi\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    # Fetch data from the dataset\n",
        "    def __getitem__(self, idx):\n",
        "        user, movie_sequence = self.data[idx]\n",
        "        # Directly index into the vocabularies\n",
        "        movie_data = [self.movie_vocab_stoi[item] for item in movie_sequence]\n",
        "        user_data = self.user_vocab_stoi[user]\n",
        "        return torch.tensor(movie_data), torch.tensor(user_data)\n",
        "\n",
        "\n",
        "# Collate function and padding\n",
        "def collate_batch(batch):\n",
        "    movie_list = [item[0] for item in batch]\n",
        "    user_list = [item[1] for item in batch]\n",
        "    return pad_sequence(movie_list, padding_value=movie_vocab_stoi['<unk>'], batch_first=True), torch.stack(user_list)\n",
        "\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "# Create instances of your Dataset for each set\n",
        "train_dataset = MovieSeqDataset(train_data_raw, movie_vocab_stoi, user_vocab_stoi)\n",
        "val_dataset = MovieSeqDataset(test_data_raw, movie_vocab_stoi, user_vocab_stoi)\n",
        "# Create DataLoaders\n",
        "train_iter = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
        "                        shuffle=True, collate_fn=collate_batch)\n",
        "val_iter = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n",
        "                      shuffle=False, collate_fn=collate_batch)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRSuW2NXAkfk"
      },
      "source": [
        "# 2. Model Definition\n",
        "We will define and initialize our model. Then the model will be trained with our previously generated dataset.\n",
        "## 2.1 Positional Encoder\n",
        "We start by defining the positional encoder, which is crucial for sequence-based models like the Transformer. This encoder will capture the positions of movie interactions in our sequences, thus embedding the order information that the Transformer model needs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "YIOSMBCtAanG"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "\n",
        "        # `div_term` is used in the calculation of the sinusoidal values.\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        # Initializing positional encoding matrix with zeros.\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "\n",
        "        # Calculating the positional encodings.\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
        "        \"\"\"\n",
        "        x = x + self.pe[:x.size(0)]\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4wtPnqQAsOU"
      },
      "source": [
        "## 2.2 Transformer Model\n",
        "Following the definition of our positional encoder, we then establish our transformer model. This model takes both the user id and the movie id sequence as input, and it is responsible for generating the output movie predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Zef8tq8NAo7M"
      },
      "outputs": [],
      "source": [
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, ntoken: int, nuser: int, d_model: int, nhead: int, d_hid: int,\n",
        "                 nlayers: int, dropout: float = 0.5):\n",
        "        super().__init__()\n",
        "        self.model_type = 'Transformer'\n",
        "        # positional encoder\n",
        "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
        "\n",
        "        # Multihead attention mechanism.\n",
        "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
        "\n",
        "        # Embedding layers\n",
        "        self.movie_embedding = nn.Embedding(ntoken, d_model)\n",
        "        self.user_embedding = nn.Embedding(nuser, d_model)\n",
        "\n",
        "        # Defining the size of the input to the model.\n",
        "        self.d_model = d_model\n",
        "\n",
        "        # Linear layer to map the output tomovie vocabulary.\n",
        "        self.linear = nn.Linear(2*d_model, ntoken)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self) -> None:\n",
        "        # Initializing the weights of the embedding and linear layers.\n",
        "        initrange = 0.1\n",
        "        self.movie_embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.user_embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.linear.bias.data.zero_()\n",
        "        self.linear.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src: Tensor, user: Tensor, src_mask: Tensor = None) -> Tensor:\n",
        "        # Embedding movie ids and userid\n",
        "        movie_embed = self.movie_embedding(src) * math.sqrt(self.d_model)\n",
        "        user_embed = self.user_embedding(user) * math.sqrt(self.d_model)\n",
        "\n",
        "        # positional encoding\n",
        "        movie_embed = self.pos_encoder(movie_embed)\n",
        "\n",
        "        # generating output with final layers\n",
        "        output = self.transformer_encoder(movie_embed, src_mask)\n",
        "\n",
        "        # Expand user_embed tensor along the sequence length dimension\n",
        "        user_embed = user_embed.expand(-1, output.size(1), -1)\n",
        "\n",
        "        # Concatenate user embeddings with transformer output\n",
        "        output = torch.cat((output, user_embed), dim=-1)\n",
        "\n",
        "        output = self.linear(output)\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3M5XCLFG_LLi"
      },
      "source": [
        "Following the model definitions, we proceed to initialize our model using a set of arbitrarily selected hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8pEgP1gg-re5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "154c2da7-fdb7-4f9d-8f32-e4c0ec1f1f66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        }
      ],
      "source": [
        "ntokens = len(movie_vocab)  # size of vocabulary\n",
        "nusers = len(user_vocab)\n",
        "emsize = 128  # embedding dimension\n",
        "d_hid = 128  # dimension of the feedforward network model\n",
        "nlayers = 2  # number of ``nn.TransformerEncoderLayer``\n",
        "nhead = 2  # number of heads in ``nn.MultiheadAttention``\n",
        "dropout = 0.2  # dropout probability\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = TransformerModel(ntokens, nusers, emsize, nhead, d_hid, nlayers, dropout).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "lr = 1.0  # learning rate\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c8xnSds_Pf-"
      },
      "source": [
        "# 3. Train & Evaluation\n",
        "We're now ready to kick off the training process with our model, where it will learn from the dataset we've prepared. Following the training phase, we'll evaluate how well our model performs on unseen data to check its effectiveness.\n",
        "## 3.1 Train Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "gW7vxqTV_Kn-"
      },
      "outputs": [],
      "source": [
        "def train(model: nn.Module, train_iter, epoch) -> None:\n",
        "    # Switch to training mode\n",
        "    model.train()\n",
        "    total_loss = 0.\n",
        "    log_interval = 200\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i, (movie_data, user_data) in enumerate(train_iter):\n",
        "        # Load movie sequence and user id\n",
        "        movie_data, user_data = movie_data.to(device), user_data.to(device)\n",
        "        user_data = user_data.reshape(-1, 1)\n",
        "\n",
        "        # Split movie sequence to inputs and targets\n",
        "        inputs, targets = movie_data[:, :-1], movie_data[:, 1:]\n",
        "        targets_flat = targets.reshape(-1)\n",
        "\n",
        "        # Predict movies\n",
        "        output = model(inputs, user_data)\n",
        "        output_flat = output.reshape(-1, ntokens)\n",
        "\n",
        "        # Backpropogation process\n",
        "        loss = criterion(output_flat, targets_flat)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        # Results\n",
        "        if i % log_interval == 0 and i > 0:\n",
        "            lr = scheduler.get_last_lr()[0]\n",
        "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
        "            cur_loss = total_loss / log_interval\n",
        "            ppl = math.exp(cur_loss)\n",
        "            print(f'| epoch {epoch:3d} '\n",
        "                  f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | '\n",
        "                  f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n",
        "            total_loss = 0\n",
        "            start_time = time.time()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKnPqYte_6si"
      },
      "source": [
        "## 3.2 Evaluation Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ex23S0dK_kM3"
      },
      "outputs": [],
      "source": [
        "def evaluate(model: nn.Module, eval_data: Tensor) -> float:\n",
        "    # Switch the model to evaluation mode.\n",
        "    # This is necessary for layers like dropout,\n",
        "    model.eval()\n",
        "    total_loss = 0.\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (movie_data, user_data) in enumerate(eval_data):\n",
        "            # Load movie sequence and user id\n",
        "            movie_data, user_data = movie_data.to(device), user_data.to(device)\n",
        "            user_data = user_data.reshape(-1, 1)\n",
        "            # Split movie sequence to inputs and targets\n",
        "            inputs, targets = movie_data[:, :-1], movie_data[:, 1:]\n",
        "            targets_flat = targets.reshape(-1)\n",
        "            # Predict movies\n",
        "            output = model(inputs, user_data)\n",
        "            output_flat = output.reshape(-1, ntokens)\n",
        "            # Calculate loss\n",
        "            loss = criterion(output_flat, targets_flat)\n",
        "            total_loss += loss.item()\n",
        "    return total_loss / (len(eval_data) - 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJNdsU06_2ky"
      },
      "source": [
        "## 3.3 Train & Evaluation Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGs7vxT0_18W",
        "outputId": "0ad1b8dc-2fbb-4430-f646-852a4d111e72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 lr 1.00 | ms/batch 15.72 | loss  7.80 | ppl  2429.50\n",
            "| epoch   1 lr 1.00 | ms/batch 11.07 | loss  7.61 | ppl  2025.68\n",
            "| epoch   1 lr 1.00 | ms/batch 11.12 | loss  7.58 | ppl  1966.73\n",
            "| epoch   1 lr 1.00 | ms/batch 14.36 | loss  7.55 | ppl  1899.99\n",
            "| epoch   1 lr 1.00 | ms/batch 13.62 | loss  7.53 | ppl  1858.17\n",
            "| epoch   1 lr 1.00 | ms/batch 10.99 | loss  7.49 | ppl  1786.38\n",
            "| epoch   1 lr 1.00 | ms/batch 10.97 | loss  7.34 | ppl  1540.54\n",
            "| epoch   1 lr 1.00 | ms/batch 11.07 | loss  7.18 | ppl  1309.86\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time: 22.68s | valid loss  7.02 | valid ppl  1122.55\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   2 lr 0.95 | ms/batch 14.38 | loss  6.93 | ppl  1021.87\n",
            "| epoch   2 lr 0.95 | ms/batch 10.94 | loss  6.80 | ppl   895.99\n",
            "| epoch   2 lr 0.95 | ms/batch 11.00 | loss  6.73 | ppl   836.35\n",
            "| epoch   2 lr 0.95 | ms/batch 10.96 | loss  6.66 | ppl   782.24\n",
            "| epoch   2 lr 0.95 | ms/batch 11.28 | loss  6.61 | ppl   744.49\n",
            "| epoch   2 lr 0.95 | ms/batch 15.28 | loss  6.57 | ppl   713.32\n",
            "| epoch   2 lr 0.95 | ms/batch 10.91 | loss  6.54 | ppl   689.87\n",
            "| epoch   2 lr 0.95 | ms/batch 11.06 | loss  6.50 | ppl   665.39\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time: 21.80s | valid loss  6.52 | valid ppl   679.03\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   3 lr 0.90 | ms/batch 11.34 | loss  6.38 | ppl   587.44\n",
            "| epoch   3 lr 0.90 | ms/batch 15.22 | loss  6.34 | ppl   569.59\n",
            "| epoch   3 lr 0.90 | ms/batch 11.12 | loss  6.33 | ppl   561.88\n",
            "| epoch   3 lr 0.90 | ms/batch 10.93 | loss  6.31 | ppl   551.29\n",
            "| epoch   3 lr 0.90 | ms/batch 11.18 | loss  6.30 | ppl   546.21\n",
            "| epoch   3 lr 0.90 | ms/batch 11.08 | loss  6.28 | ppl   534.61\n",
            "| epoch   3 lr 0.90 | ms/batch 13.73 | loss  6.28 | ppl   533.39\n",
            "| epoch   3 lr 0.90 | ms/batch 12.45 | loss  6.26 | ppl   522.48\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time: 22.12s | valid loss  6.37 | valid ppl   583.97\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   4 lr 0.86 | ms/batch 11.60 | loss  6.16 | ppl   473.99\n",
            "| epoch   4 lr 0.86 | ms/batch 11.09 | loss  6.13 | ppl   460.12\n",
            "| epoch   4 lr 0.86 | ms/batch 13.85 | loss  6.13 | ppl   458.11\n",
            "| epoch   4 lr 0.86 | ms/batch 12.61 | loss  6.13 | ppl   459.27\n",
            "| epoch   4 lr 0.86 | ms/batch 10.75 | loss  6.13 | ppl   459.10\n",
            "| epoch   4 lr 0.86 | ms/batch 10.95 | loss  6.13 | ppl   459.11\n",
            "| epoch   4 lr 0.86 | ms/batch 11.09 | loss  6.11 | ppl   450.50\n",
            "| epoch   4 lr 0.86 | ms/batch 11.87 | loss  6.12 | ppl   454.21\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   4 | time: 22.06s | valid loss  6.30 | valid ppl   544.52\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   5 lr 0.81 | ms/batch 11.40 | loss  6.01 | ppl   406.26\n",
            "| epoch   5 lr 0.81 | ms/batch 10.98 | loss  5.99 | ppl   400.57\n",
            "| epoch   5 lr 0.81 | ms/batch 11.33 | loss  6.00 | ppl   403.32\n",
            "| epoch   5 lr 0.81 | ms/batch 11.58 | loss  6.00 | ppl   404.98\n",
            "| epoch   5 lr 0.81 | ms/batch 14.52 | loss  6.01 | ppl   407.68\n",
            "| epoch   5 lr 0.81 | ms/batch 11.18 | loss  6.01 | ppl   406.72\n",
            "| epoch   5 lr 0.81 | ms/batch 11.06 | loss  6.01 | ppl   406.23\n",
            "| epoch   5 lr 0.81 | ms/batch 11.06 | loss  6.01 | ppl   408.78\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   5 | time: 21.38s | valid loss  6.26 | valid ppl   523.34\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   6 lr 0.77 | ms/batch 15.15 | loss  5.91 | ppl   369.97\n",
            "| epoch   6 lr 0.77 | ms/batch 10.85 | loss  5.90 | ppl   364.02\n",
            "| epoch   6 lr 0.77 | ms/batch 10.99 | loss  5.90 | ppl   365.66\n",
            "| epoch   6 lr 0.77 | ms/batch 10.92 | loss  5.91 | ppl   367.68\n",
            "| epoch   6 lr 0.77 | ms/batch 11.01 | loss  5.91 | ppl   369.73\n",
            "| epoch   6 lr 0.77 | ms/batch 15.16 | loss  5.91 | ppl   368.04\n",
            "| epoch   6 lr 0.77 | ms/batch 11.37 | loss  5.92 | ppl   371.41\n",
            "| epoch   6 lr 0.77 | ms/batch 11.01 | loss  5.91 | ppl   369.83\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   6 | time: 21.92s | valid loss  6.24 | valid ppl   512.49\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   7 lr 0.74 | ms/batch 11.37 | loss  5.83 | ppl   339.45\n",
            "| epoch   7 lr 0.74 | ms/batch 14.85 | loss  5.82 | ppl   337.88\n",
            "| epoch   7 lr 0.74 | ms/batch 11.54 | loss  5.81 | ppl   334.67\n",
            "| epoch   7 lr 0.74 | ms/batch 10.99 | loss  5.82 | ppl   338.30\n",
            "| epoch   7 lr 0.74 | ms/batch 11.03 | loss  5.83 | ppl   341.61\n",
            "| epoch   7 lr 0.74 | ms/batch 11.04 | loss  5.83 | ppl   341.25\n",
            "| epoch   7 lr 0.74 | ms/batch 12.93 | loss  5.84 | ppl   344.62\n",
            "| epoch   7 lr 0.74 | ms/batch 13.43 | loss  5.85 | ppl   346.44\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   7 | time: 22.06s | valid loss  6.23 | valid ppl   507.79\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   8 lr 0.70 | ms/batch 14.63 | loss  5.74 | ppl   311.67\n",
            "| epoch   8 lr 0.70 | ms/batch 12.67 | loss  5.74 | ppl   311.54\n",
            "| epoch   8 lr 0.70 | ms/batch 14.85 | loss  5.75 | ppl   313.31\n",
            "| epoch   8 lr 0.70 | ms/batch 11.43 | loss  5.77 | ppl   320.04\n",
            "| epoch   8 lr 0.70 | ms/batch 11.05 | loss  5.77 | ppl   322.03\n",
            "| epoch   8 lr 0.70 | ms/batch 10.99 | loss  5.77 | ppl   320.28\n",
            "| epoch   8 lr 0.70 | ms/batch 11.10 | loss  5.78 | ppl   323.74\n",
            "| epoch   8 lr 0.70 | ms/batch 13.00 | loss  5.79 | ppl   327.84\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   8 | time: 23.04s | valid loss  6.22 | valid ppl   504.22\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   9 lr 0.66 | ms/batch 11.27 | loss  5.69 | ppl   295.19\n",
            "| epoch   9 lr 0.66 | ms/batch 11.03 | loss  5.68 | ppl   293.02\n",
            "| epoch   9 lr 0.66 | ms/batch 10.99 | loss  5.69 | ppl   296.75\n",
            "| epoch   9 lr 0.66 | ms/batch 12.87 | loss  5.71 | ppl   301.30\n",
            "| epoch   9 lr 0.66 | ms/batch 13.55 | loss  5.70 | ppl   299.07\n",
            "| epoch   9 lr 0.66 | ms/batch 10.96 | loss  5.72 | ppl   305.55\n",
            "| epoch   9 lr 0.66 | ms/batch 11.13 | loss  5.73 | ppl   308.49\n",
            "| epoch   9 lr 0.66 | ms/batch 10.88 | loss  5.74 | ppl   311.73\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   9 | time: 21.40s | valid loss  6.22 | valid ppl   503.21\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  10 lr 0.63 | ms/batch 14.38 | loss  5.65 | ppl   284.31\n",
            "| epoch  10 lr 0.63 | ms/batch 11.09 | loss  5.62 | ppl   276.80\n",
            "| epoch  10 lr 0.63 | ms/batch 11.02 | loss  5.64 | ppl   282.07\n",
            "| epoch  10 lr 0.63 | ms/batch 10.83 | loss  5.65 | ppl   284.20\n",
            "| epoch  10 lr 0.63 | ms/batch 10.90 | loss  5.67 | ppl   288.62\n",
            "| epoch  10 lr 0.63 | ms/batch 15.12 | loss  5.68 | ppl   293.45\n",
            "| epoch  10 lr 0.63 | ms/batch 11.31 | loss  5.68 | ppl   292.17\n",
            "| epoch  10 lr 0.63 | ms/batch 10.95 | loss  5.70 | ppl   297.66\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  10 | time: 21.76s | valid loss  6.22 | valid ppl   502.84\n",
            "-----------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "best_val_loss = float('inf')\n",
        "epochs = 10\n",
        "\n",
        "with TemporaryDirectory() as tempdir:\n",
        "    best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        epoch_start_time = time.time()\n",
        "\n",
        "        # Training\n",
        "        train(model, train_iter, epoch)\n",
        "\n",
        "        # Evaluation\n",
        "        val_loss = evaluate(model, val_iter)\n",
        "\n",
        "        # Compute the perplexity of the validation loss\n",
        "        val_ppl = math.exp(val_loss)\n",
        "        elapsed = time.time() - epoch_start_time\n",
        "\n",
        "        # Results\n",
        "        print('-' * 89)\n",
        "        print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n",
        "            f'valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}')\n",
        "        print('-' * 89)\n",
        "\n",
        "        # Save best model\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "        scheduler.step()\n",
        "    model.load_state_dict(torch.load(best_model_params_path)) # load best model states"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDZJozuLjIUw"
      },
      "source": [
        "## 3.4 Generating Popular Movie Recommendations as Baseline\n",
        "In order to compare our model success a baseline recommendation method is required. One of the easiest recommendation method is popular movie recommendation which is obtained by most frequent and highly rated movies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_buSM6b5YHuK"
      },
      "outputs": [],
      "source": [
        "def get_popular_movies(df_ratings):\n",
        "  # Calculate the number of ratings for each movie\n",
        "  rating_counts = df_ratings['movie_id'].value_counts().reset_index()\n",
        "  rating_counts.columns = ['movie_id', 'rating_count']\n",
        "\n",
        "  # Get the most frequently rated movies\n",
        "  min_ratings_threshold = rating_counts['rating_count'].quantile(0.95)\n",
        "\n",
        "  # Filter movies based on the minimum number of ratings\n",
        "  popular_movies = ratings.merge(rating_counts, on='movie_id')\n",
        "  popular_movies = popular_movies[popular_movies['rating_count'] >= min_ratings_threshold]\n",
        "\n",
        "\n",
        "  # Calculate the average rating for each movie\n",
        "  average_ratings = popular_movies.groupby('movie_id')['rating'].mean().reset_index()\n",
        "  # Get the top 10 rated movies\n",
        "  top_10_movies = list(average_ratings.sort_values('rating', ascending=False).head(10).movie_id.values)\n",
        "  return top_10_movies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDY4JvP-o3xZ",
        "outputId": "9f7eea35-fc14-48ce-b988-bc2aea6be20b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Shawshank Redemption, The (1994)',\n",
              " 'Godfather, The (1972)',\n",
              " 'Usual Suspects, The (1995)',\n",
              " \"Schindler's List (1993)\",\n",
              " 'Raiders of the Lost Ark (1981)',\n",
              " 'Star Wars: Episode IV - A New Hope (1977)',\n",
              " 'Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1963)',\n",
              " 'Casablanca (1942)',\n",
              " 'Sixth Sense, The (1999)',\n",
              " \"One Flew Over the Cuckoo's Nest (1975)\"]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "top_10_movies = get_popular_movies(ratings)\n",
        "[movie_title_dict[movie] for movie in top_10_movies]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9edNBt-ijnA"
      },
      "source": [
        "## 3.5 Recommendations Result Comparison\n",
        "Like the evaluation function we will iterate our validation dataset and store recommendation results in lists to compare them with normalized discounted gain(NDCG) metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "7XtOtvbCamoA"
      },
      "outputs": [],
      "source": [
        "# Movie id decoder\n",
        "movie_vocab_itos = movie_vocab.get_itos()\n",
        "\n",
        "# A placeholders to store results of recommendations\n",
        "transformer_reco_results = list()\n",
        "popular_reco_results = list()\n",
        "\n",
        "# Get top 10 movies\n",
        "k = 10\n",
        "# Iterate over the validation data\n",
        "for i, (movie_data, user_data) in enumerate(val_iter):\n",
        "    # Feed the input and get the outputs\n",
        "    movie_data, user_data = movie_data.to(device), user_data.to(device)\n",
        "    user_data = user_data.reshape(-1, 1)\n",
        "    inputs, targets = movie_data[:, :-1], movie_data[:, 1:]\n",
        "    output = model(inputs, user_data)\n",
        "    output_flat = output.reshape(-1, ntokens)\n",
        "    targets_flat = targets.reshape(-1)\n",
        "\n",
        "    # Reshape the output_flat to get top predictions\n",
        "    outputs = output_flat.reshape(output_flat.shape[0] // inputs.shape[1],\n",
        "                                  inputs.shape[1],\n",
        "                                  output_flat.shape[1])[: , -1, :]\n",
        "    # k + len(inputs) = 13 movies obtained\n",
        "    # In order to prevent to recommend already watched movies\n",
        "    values, indices = outputs.topk(k + inputs.shape[1], dim=-1)\n",
        "\n",
        "    for sub_sequence, sub_indice_org in zip(movie_data, indices):\n",
        "        sub_indice_org = sub_indice_org.cpu().detach().numpy()\n",
        "        sub_sequence = sub_sequence.cpu().detach().numpy()\n",
        "\n",
        "        # Generate mask array to eliminate already watched movies\n",
        "        mask = np.isin(sub_indice_org, sub_sequence[:-1], invert=True)\n",
        "\n",
        "        # After masking get top k movies\n",
        "        sub_indice = sub_indice_org[mask][:k]\n",
        "\n",
        "        # Generate results array\n",
        "        transformer_reco_result = np.isin(sub_indice, sub_sequence[-1]).astype(int)\n",
        "\n",
        "        # Decode movie to search in popular movies\n",
        "        target_movie_decoded = movie_vocab_itos[sub_sequence[-1]]\n",
        "        popular_reco_result = np.isin(top_10_movies, target_movie_decoded).astype(int)\n",
        "\n",
        "        transformer_reco_results.append(transformer_reco_result)\n",
        "        popular_reco_results.append(popular_reco_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWid7M9fbx7g"
      },
      "source": [
        "Comparing baseline method vs transformer model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DYVH2JmpHrW",
        "outputId": "f51e976c-a7a5-4629-fa1f-b80f0910bba8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformer NDCG result at top 3: 0.0543\n",
            "Popular recommendation NDCG result at top 3: 0.0046\n",
            "\n",
            "\n",
            "Transformer NDCG result at top 5: 0.0685\n",
            "Popular recommendation NDCG result at top 5: 0.0064\n",
            "\n",
            "\n",
            "Transformer NDCG result at top 10: 0.0914\n",
            "Popular recommendation NDCG result at top 10: 0.0094\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import ndcg_score\n",
        "\n",
        "# Since we have already sorted our recommendations\n",
        "# An array that represent our recommendation scores is used.\n",
        "representative_array = [[i for i in range(k, 0, -1)]] * len(transformer_reco_results)\n",
        "\n",
        "for k in [3, 5, 10]:\n",
        "  transformer_result = ndcg_score(transformer_reco_results,\n",
        "                                  representative_array, k=k)\n",
        "  popular_result = ndcg_score(popular_reco_results,\n",
        "                              representative_array, k=k)\n",
        "\n",
        "  print(f\"Transformer NDCG result at top {k}: {round(transformer_result, 4)}\")\n",
        "  print(f\"Popular recommendation NDCG result at top {k}: {round(popular_result, 4)}\\n\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rvyhAueb2f9"
      },
      "source": [
        "Here we have seen our model results are approximately 10 times better than popular movie recommendation at NDCG metric. A function to generate recommendation for single data is given below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "XAyDjSxV_pZa"
      },
      "outputs": [],
      "source": [
        "def generate_recommendation(user_id, movie_sequence, k=10):\n",
        "    model.eval()\n",
        "    input_sequence = movie_sequence[:-1]\n",
        "    # Tokenize and numerically encode the user id and movie sequence\n",
        "    user_tensor = torch.tensor(user_vocab_stoi[user_id])\n",
        "    movie_tensor = torch.tensor([[movie_vocab_stoi[movie_id]] for movie_id in input_sequence])\n",
        "    # Shape: [1, 1]\n",
        "    user_tensor = user_tensor.unsqueeze(0).to(device)\n",
        "    user_tensor = user_tensor.view(user_tensor.shape[0], 1)\n",
        "\n",
        "    # Shape: [1, seq_length]\n",
        "    movie_tensor = movie_tensor.unsqueeze(0).to(device)[0]\n",
        "    movie_tensor = movie_tensor.view(1, movie_tensor.shape[0])\n",
        "\n",
        "    # Pass the tensors through the model\n",
        "    with torch.no_grad():\n",
        "        predictions = model(movie_tensor, user_tensor)\n",
        "\n",
        "    # The output is a probability distribution over the next movie.\n",
        "    # Topk to get most probable movies\n",
        "    values, indices = predictions.topk(k + len(input_sequence), dim=-1)\n",
        "    # Eliminate already watched movies\n",
        "    indices = [indice for indice in indices[-1, :][0] if indice not in movie_tensor][:k]\n",
        "    predicted_movies = [movie_title_dict[movie_vocab.get_itos()[movie]] for movie in indices]\n",
        "    return predicted_movies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcuSBAP5fGXb",
        "outputId": "5bf16447-671b-49dd-c192-ca211216400a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Sequence:\n",
            "-Rush Hour (1998)\n",
            "-Face/Off (1997)\n",
            "-GoldenEye (1995)\n",
            "Recomendations:\n",
            "-True Lies (1994)\n",
            "-Mummy, The (1999)\n",
            "-Patriot Games (1992)\n",
            "-Indiana Jones and the Temple of Doom (1984)\n",
            "-Long Kiss Goodnight, The (1996)\n",
            "-Stargate (1994)\n",
            "-Blade (1998)\n",
            "-Fallen (1998)\n",
            "-Desperado (1995)\n",
            "-Romancing the Stone (1984)\n"
          ]
        }
      ],
      "source": [
        "row_iter = test_data_raw[59233]\n",
        "print(\"Input Sequence:\")\n",
        "print(\"-\" + \"\\n-\".join([movie_title_dict[ea_movie] for ea_movie in row_iter[1][:-1]]))\n",
        "recos = '\\n-'.join(generate_recommendation(row_iter[0],row_iter[1]))\n",
        "\n",
        "print(f\"Recomendations:\\n-{recos}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}